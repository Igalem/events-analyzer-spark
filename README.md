# 🚀 Apache Spark Event Stream Analysis

<img src="https://upload.wikimedia.org/wikipedia/commons/f/f3/Apache_Spark_logo.svg" alt="Apache Spark Logo" width="300"/>


## 📋 Overview
This project analyzes a simulated stream of events generated by an imaginary service using **[Apache Spark](https://spark.apache.org/)**.<br>
It processes these events to produce insights such as top converting users, conversion metrics, and user behavior patterns. <br>
The solution is implemented in **PySpark** and is designed to run locally without the need for a cluster.

---

## 📥 Input Data
The input consists of a simulated event stream stored in a file. Each event is represented as a line with the following fields:

- **🔗 Url**: The URL visited by the user.
- **👤 User_id**: A unique identifier for the user.
- **⏱️ Timestamp**: The timestamp of the event.
- **📄 Event_Type**: The type of event. Possible values:
  - `start_session`
  - `in-page` (occurs on every URL hit)
  - `conversion`
  - `end_session`

### 📝 Sample Data
```csv
event_id,user_id,timestamp,event_type,url
f26f5621-02cb-43a6-b542-6616945d7bf9,48986,2024-12-13 00:00:30,end_session,https://myfrontsite.com/contact
cccd8c23-c642-40bf-8631-b90ca2db8cf0,37016,2024-12-13 00:00:37,in-page,https://myfrontsite.com/contact
15d5cbcf-dd07-4b83-8f5b-c7ad133e4c49,32549,2024-12-13 00:02:35,conversion,https://myfrontsite.com/home
e8dbb325-f65b-48ac-b063-890f6efe6eb1,62972,2024-12-13 00:03:59,in-page,https://myfrontsite.com/checkout
8ca1a4d6-8a79-4996-add5-6b00b4959744,38252,2024-12-13 00:04:17,conversion,https://myfrontsite.com/home
```

🛠️ Implementation
Environment Setup

Install dependencies:

```bash
pip install -r requirements.txt
```

▶️ Run the Application

1. Clone this repository
2. You can use the located events.csv file located in 'src' folder or recreate new source file using 'events_generator.py' python file.

```bash
python src/events_generator.py
```

Ensure the events.csv input file is available at the specified path.


Open Jupyter Lab:

```bash
jupyter lab
```

Run the PySpark script:

Open the notebook named: events.ipynb
Run all Steps.

Results will be saved in the specified output directory ('output/').

Enjoy! 🙂

